{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shibozhang/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "import pickle\n",
    "from stru_utils_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rmFilesInFolder(folder):\n",
    "#     remove files in folder\n",
    "    import os, shutil\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path): \n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision stump scikit-learn wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predWeakClf(X,y,d=None):\n",
    "# eg: predWeakClf(xyFNFArr[:,f],xyFNFArr[:,-1])\n",
    "# input type:\n",
    "#     X: ndarray\n",
    "#     y: ndarray\n",
    "# output type:\n",
    "#     pred: ndarray\n",
    "\n",
    "    h = DecisionTreeClassifier(max_depth=1)\n",
    "    X = X.reshape(-1, 1)\n",
    "    h.fit(X, y, sample_weight=d)\n",
    "    pred = h.predict(X)\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "\n",
    "# mdl saves the modified weak classifier model, \n",
    "# featFile saves which feature each weak classifier is using\n",
    "\n",
    "def saveWeakClf(X, y, mdlname, feat, beta, configFile, d=None):\n",
    "#     X is one single feature\n",
    "#     feat is the index of this input feature\n",
    "#     beta is \n",
    "    h = DecisionTreeClassifier(max_depth=1)\n",
    "    X = X.reshape(-1, 1)\n",
    "    h.fit(X, y, sample_weight=d)\n",
    "    \n",
    "    # save the model to disk\n",
    "    pickle.dump(h, open(mdlname, 'wb'))\n",
    "    \n",
    "    with open(configFile, 'w') as text_file:\n",
    "        text_file.write(str(feat))   \n",
    "        text_file.write('\\n')   \n",
    "        text_file.write(str(beta))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# mdl saves the modified weak classifier model, \n",
    "# configFile saves which feature each weak classifier is using and the beta for each classifier\n",
    "\n",
    "def loadWeakClf(mdlname, configFile):\n",
    "    # load the model from disk\n",
    "    loaded_model = pickle.load(open(mdlname, 'rb'))\n",
    "    \n",
    "    with open(configFile, \"r\") as f:\n",
    "        array = []\n",
    "        for line in f:\n",
    "            array.append(line)\n",
    "            \n",
    "    feat = array[0]\n",
    "    beta = array[1]\n",
    "    \n",
    "    return loaded_model, feat, beta\n",
    "\n",
    "\n",
    "# test case\n",
    "# loaded_model, feat, beta = (loadWeakClf('./model/0.sav', './model/0_feat.sav'))\n",
    "# print(feat)\n",
    "# print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n################################# test case #############################\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weval(yLabel,yPred,w_norm):\n",
    "#     \n",
    "#     calculate error\n",
    "# \n",
    "# input type:\n",
    "#     yLabel: ndarray\n",
    "#     yPred: ndarray\n",
    "#     w_norm: ndarray\n",
    "\n",
    "    return np.dot(np.absolute(yLabel - yPred), w_norm)\n",
    "\n",
    "'''\n",
    "################################# test case #############################\n",
    "'''\n",
    "# weval(np.asarray([0,1,0,1,1]),np.asarray([1,1,1,0,1]),np.asarray([0.2,0.1,0.3,.2,.2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.02222222,  0.4       ,  0.04444444]),\n",
       " array([ 0.        ,  0.11111111,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wUpdate(beta, t, errmin, w_norm, samples, yLabel, yPred):\n",
    "# \n",
    "# update weights and betas\n",
    "# \n",
    "    beta[t] = errmin/(1-errmin)\n",
    "    \n",
    "    w = np.multiply(w_norm, np.power(beta[t], np.ones(samples) - np.absolute(yLabel - yPred)))\n",
    "    return w, beta\n",
    "\n",
    "'''\n",
    "################################# test case #############################\n",
    "## step by step manual result for this test code\n",
    "##\n",
    "## np.absolute(yLabel - yPred) = [0,1,0]\n",
    "## np.ones(samples) - np.absolute(yLabel - yPred) = [1,0,1]\n",
    "## np.power(beta[t], np.ones(samples) - np.absolute(yLabel - yPred)) = [0.1111,1,0.1111]\n",
    "## w = [ 0.02222222,  0.4       ,  0.04444444]\n",
    "##\n",
    "#########################################################################\n",
    "'''\n",
    "wUpdate(beta=np.zeros(10), t=1, errmin=0.1, w_norm=np.array([0.2,0.4,0.4]), samples=3, yLabel=np.array([0,1,0]), yPred=np.array([0,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadDataset(dataset):\n",
    "\n",
    "\n",
    "    if dataset == 'feeding':\n",
    "\n",
    "        protocol = 'IS'\n",
    "\n",
    "        pathProt = {'IS':'IS', 'US':'US', 'Field':'Field/testdata_labeled'}\n",
    "\n",
    "        fgFeatFolder = '../WillSense/code/WS/'+pathProt[protocol]+'/feature/feedingGestures/'\n",
    "        file = fgFeatFolder + \"features.csv\"\n",
    "        fgDf = pd.read_csv(file)\n",
    "        fgDf = fgDf.dropna()\n",
    "\n",
    "        nfgFeatFolder = '../WillSense/code/WS/'+pathProt[protocol]+'/feature/nonFeedingGestures/'\n",
    "        file = nfgFeatFolder + \"features.csv\"\n",
    "        nfgDf = pd.read_csv(file)\n",
    "        nfgDf = nfgDf.dropna()\n",
    "\n",
    "\n",
    "        # Feeding\n",
    "        fgFeatsArr = fgDf.as_matrix()\n",
    "        xyFgArr = np.hstack((fgFeatsArr, np.ones((fgFeatsArr.shape[0],1))))\n",
    "\n",
    "        # Non-feeding\n",
    "        nfgFeatsArr = nfgDf.as_matrix()\n",
    "\n",
    "        balancePN = 1\n",
    "\n",
    "        if balancePN:\n",
    "        # balance pos and neg samples, here #pos < #neg:\n",
    "            nfgFeatsArr = nfgFeatsArr[:fgFeatsArr.shape[0],:]\n",
    "            xyNfgArr = np.hstack((nfgFeatsArr, np.zeros((nfgFeatsArr.shape[0],1))))\n",
    "        else:\n",
    "            xyNfgArr = np.hstack((nfgFeatsArr, np.zeros((nfgFeatsArr.shape[0],1))))\n",
    "\n",
    "\n",
    "        xyFNFArr = np.vstack((xyFgArr,xyNfgArr))\n",
    "\n",
    "        np.random.shuffle(xyFNFArr)#no return function\n",
    "\n",
    "\n",
    "        XY = xyFNFArr\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        data = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "        X_T = data[0]\n",
    "        Y_T = data[1]\n",
    "\n",
    "        XY = np.hstack((X_T,Y_T.reshape(-1, 1)))\n",
    "    #     np.savetxt('breast_cancer.csv', XY, delimiter=',')\n",
    "    \n",
    "    return XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadTrnTestDataset(dataset):\n",
    "\n",
    "\n",
    "    XY = loadDataset(dataset)\n",
    "    \n",
    "    XYPos =  XY[np.where(XY[:,-1]==1)[0],:]\n",
    "    XYNeg =  XY[np.where(XY[:,-1]==0)[0],:]\n",
    "\n",
    "    XYPosTrn, XYPosTest = tt_split(XYPos, 0.3)\n",
    "    XYNegTrn, XYNegTest = tt_split(XYNeg, 0.3)\n",
    "\n",
    "    XYTrn = np.vstack((XYPosTrn,XYNegTrn))\n",
    "    XYTest = np.vstack((XYPosTest,XYNegTest))\n",
    "    \n",
    "    return XYTrn, XYTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def XYTrnUpdateWithTopNFeats(XYTrn, featList, nFeats):\n",
    "    \n",
    "#       select first n features in featList for training set\n",
    "    feats = featList[:nFeats]\n",
    "    XYTrnNFeat = np.hstack((XYTrn[:,feats], XYTrn[:,-1].reshape([-1,1])))\n",
    "\n",
    "    return XYTrnNFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateTestSetbySelPosSamples(XYTestNFeat, yRes):\n",
    "    \n",
    "    indList = []\n",
    "    for i in range(len(yRes)):\n",
    "        if yRes[i] == 1:\n",
    "            indList.append(i)\n",
    "\n",
    "    print(indList)\n",
    "    XYTestNFeat_1 = XYTestNFeat[indList,:]\n",
    "    \n",
    "    return XYTestNFeat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateTrnsetWithFPtrueSamples(XYCurrTrn, yRes):\n",
    "    yLabel = XYCurrTrn[:,-1]\n",
    "    indList = []\n",
    "    \n",
    "    for i in range(len(yRes)):\n",
    "        if yRes[i] == 1 and yLabel[i]==0:\n",
    "            indList.append(i)\n",
    "            \n",
    "    N = XYCurrTrn[indList,:]\n",
    "    P = XYCurrTrn[np.where(XYCurrTrn[:,-1]==1)[0],:]\n",
    "\n",
    "    XYTrn = np.vstack((P,N))\n",
    "\n",
    "    return XYTrn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.savetxt('w_norm_rec.out', w_norm_rec, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(fOptList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# yPred = predWeakClf(XY[:,4].reshape(-1, 1), yLabel, w_norm)\n",
    "# print(weval(yLabel, yPred, w_norm))\n",
    "# print(yPred-yLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in fOptList:\n",
    "#     print(list(fgDf)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module for Cascaded Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildStrongClfDefThres(XY, T , mdlpath = './mdl/'):\n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# input:\n",
    "#           XY:   features and labels\n",
    "#            T:   number of iterations, IMPORTANT PARAMETER\n",
    "#      mdlpath:   the path where the models are saved\n",
    "# \n",
    "# output:\n",
    "#   saveFinish:   1 for success, 0 for failure\n",
    "# \n",
    "# save:\n",
    "#        model\n",
    "#         fOpt:   feature index\n",
    "#         beta\n",
    "# \n",
    "\n",
    "    saveFinish = 0\n",
    "    \n",
    "    yLabel = XY[:,-1]\n",
    "    \n",
    "#     featValid = featList[:nFeats]\n",
    "#     X = XY[:,featValid]\n",
    "#     XY = np.hstack((X,XY[:,-1]))\n",
    "\n",
    "    nsamples = list(XY[:,-1]).count(0)\n",
    "    psamples = list(XY[:,-1]).count(1)\n",
    "    samples = nsamples + psamples\n",
    "    \n",
    "    # number of features\n",
    "    nFeats = XY.shape[1]-1\n",
    "    \n",
    "    featList = list(range(nFeats))\n",
    "\n",
    "    if not os.path.exists(mdlpath):\n",
    "        os.makedirs(mdlpath)\n",
    "    else:\n",
    "        rmFilesInFolder(mdlpath)\n",
    "        \n",
    "    fOptList = []\n",
    "    \n",
    "    betas = np.zeros([T])# keep record of all betas in all rounds\n",
    "#     w_norm_rec = np.zeros([T, samples])\n",
    "\n",
    "    # initialize weights\n",
    "    w = np.zeros([samples])\n",
    "    w[:nsamples] = 1/nsamples\n",
    "    w[nsamples:] = 1/psamples\n",
    "\n",
    "\n",
    "    for t in range(T):\n",
    "        # 1. normalize weights\n",
    "        w_norm = preprocessing.normalize(w, norm = 'l1')\n",
    "#         w_norm_rec[t,:] = w_norm # w_norm record\n",
    "\n",
    "        err = np.ones(nFeats)\n",
    "\n",
    "        # for each feature:\n",
    "        for f in featList:\n",
    "            # 2. train a classifier h using a single feature.\n",
    "            w_norm = w_norm.ravel()        \n",
    "\n",
    "            yPred = predWeakClf(XY[:,f].reshape(-1, 1), yLabel, w_norm)\n",
    "\n",
    "            # error calculation\n",
    "            err[f] = weval(yLabel, yPred, w_norm)\n",
    "\n",
    "        # 3. choose the classifier with lowest error\n",
    "        fOpt = np.argmin(err)\n",
    "\n",
    "#         if t%(T/10) == 0:\n",
    "#             print('fOpt: ',fOpt)\n",
    "\n",
    "        errmin = np.amin(err)    \n",
    "        \n",
    "#         if t%(T/10) == 0:\n",
    "#             print(errmin)\n",
    "\n",
    "        fOptList.append(fOpt)\n",
    "\n",
    "\n",
    "        # 4. update weights\n",
    "        w, betas = wUpdate(betas, t, errmin, w_norm, samples, yLabel, yPred)\n",
    "\n",
    "        saveWeakClf(XY[:,np.argmin(err)].reshape(-1, 1), yLabel, \n",
    "                       mdlpath+str(t)+'.sav', \n",
    "                       fOpt, betas[t], mdlpath+str(t)+'_feat.sav', \n",
    "                       w_norm)\n",
    "        \n",
    "#         if t%(T/10) == 0:\n",
    "#             print('t:',t)\n",
    "\n",
    "            \n",
    "    saveFinish = 1\n",
    "\n",
    "\n",
    "    return saveFinish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# After training with training set.\n",
    "# Load weak classifier and then build final strong classifier with default threshold, \n",
    "# meaning threshold is not adjustable.\n",
    "# Note: fOptList is basically the weak classifier h(x).\n",
    "'''\n",
    "\n",
    "# mdlpath = './model/'\n",
    "# the models are './model/(i).sav'\n",
    "\n",
    "def loadStrongClfDefThres(XY, T, mdlpath):\n",
    "    \n",
    "#     load and get weak classifiers result\n",
    "\n",
    "    yPredRec = np.zeros([T, XY.shape[0]])\n",
    "    yRes = np.zeros(XY.shape[0])\n",
    "    X = XY[:,:-1]\n",
    "    betas = np.zeros([T])# keep record of all betas in all rounds\n",
    "\n",
    "    for t in range(T):\n",
    "        h, feat, betas[t] = loadWeakClf(mdlpath+str(t)+'.sav', mdlpath+str(t)+'_feat.sav')\n",
    "        yPred = h.predict(X[:,feat].reshape(-1, 1))\n",
    "        yPredRec[t,:] = yPred\n",
    "        \n",
    "#     calc classify threshold\n",
    "\n",
    "    betas_recip = np.reciprocal(betas)\n",
    "    alphas = np.log(betas_recip)\n",
    "    clfThres = np.sum(alphas)*0.5\n",
    "    \n",
    "    yComb = np.dot(alphas, yPredRec)\n",
    "    \n",
    "#     get final result\n",
    "\n",
    "    for i in range(yComb.shape[0]):\n",
    "        if yComb[i] < clfThres:\n",
    "            yRes[i] = 0\n",
    "        else:\n",
    "            yRes[i] = 1\n",
    "    \n",
    "    return yRes, clfThres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# final strong classifier with adjustable threshold\n",
    "'''    \n",
    "\n",
    "# mdlpath = './model/'\n",
    "# the models are './model/(i).sav'\n",
    "\n",
    "\n",
    "def loadStrongClfAdjThres(XY, T, mdlpath ,clfThres):\n",
    "\n",
    "#     load and get weak classifiers result\n",
    "\n",
    "    yPredRec = np.zeros([T, XY.shape[0]])\n",
    "    yRes = np.zeros(XY.shape[0])\n",
    "    X = XY[:,:-1]\n",
    "    betas = np.zeros([T])# keep record of all betas in all rounds\n",
    "\n",
    "    for t in range(T):\n",
    "        h, feat, betas[t] = loadWeakClf(mdlpath+str(t)+'.sav', mdlpath+str(t)+'_feat.sav')\n",
    "        yPred = h.predict(X[:,feat].reshape(-1, 1))\n",
    "        yPredRec[t,:] = yPred\n",
    "        \n",
    "#     calc classify threshold\n",
    "\n",
    "    betas_recip = np.reciprocal(betas)\n",
    "    alphas = np.log(betas_recip)\n",
    "    \n",
    "    yComb = np.dot(alphas, yPredRec) \n",
    "    \n",
    "#     print(yComb)\n",
    "\n",
    "    for i in range(yComb.shape[0]):\n",
    "        if yComb[i] < clfThres:\n",
    "            yRes[i] = 0\n",
    "        else:\n",
    "            yRes[i] = 1\n",
    "    \n",
    "    return yRes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## component for cascaded clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: feeding\n",
      "\n",
      "Baseline model: KNN5\n",
      "\n",
      "Baseline model: AdaBoost\n",
      "fOpt:  38\n",
      "0.0847902097902\n",
      "t: 0\n",
      "fOpt:  13\n",
      "0.0368492958091\n",
      "t: 1\n",
      "fOpt:  38\n",
      "0.0746340412334\n",
      "t: 2\n",
      "fOpt:  13\n",
      "0.0630496577388\n",
      "t: 3\n",
      "fOpt:  38\n",
      "0.0721158669972\n",
      "t: 4\n",
      "fOpt:  13\n",
      "0.0696957617439\n",
      "t: 5\n",
      "fOpt:  38\n",
      "0.0716306073956\n",
      "t: 6\n",
      "fOpt:  13\n",
      "0.0711324557536\n",
      "t: 7\n",
      "fOpt:  38\n",
      "0.0715324340006\n",
      "t: 8\n",
      "fOpt:  13\n",
      "0.0714301456756\n",
      "t: 9\n",
      "clfThres:  13.1321457819 \n",
      "\n",
      "\n",
      "recall_pos:  0.996503496503 \n",
      "\n",
      "prec_pos:  0.748031496063 \n",
      "\n",
      "false positive rate:  0.335664335664 \n",
      "\n",
      "clfThres:  1\n",
      "recall_pos:  1.0\n",
      "prec_pos:  0.707045735476\n",
      "false positive rate:  0.414335664336 \n",
      "\n",
      "clfThres:  6\n",
      "recall_pos:  1.0\n",
      "prec_pos:  0.741893644617\n",
      "false positive rate:  0.347902097902 \n",
      "\n",
      "clfThres:  11\n",
      "recall_pos:  1.0\n",
      "prec_pos:  0.741893644617\n",
      "false positive rate:  0.347902097902 \n",
      "\n",
      "clfThres:  16\n",
      "recall_pos:  0.886363636364\n",
      "prec_pos:  0.951219512195\n",
      "false positive rate:  0.0454545454545 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shibozhang/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:22: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/shibozhang/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:20: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    datasets = ['feeding' , 'cancer']\n",
    "    dataset = datasets[0]\n",
    "    print('dataset:', dataset)\n",
    "\n",
    "    XY = loadDataset(dataset)\n",
    "    \n",
    "    X_T = XY[:,:-1]\n",
    "    Y_T = XY[:,-1]\n",
    "    \n",
    "#     XYTrn, XYTest = loadTrnTestDataset(dataset)\n",
    "#     X_T = XYTrn[:,:-1]\n",
    "#     Y_T = XYTrn[:,-1]\n",
    "    \n",
    "    ##########################################\n",
    "    #     baseline model\n",
    "    ##########################################\n",
    "\n",
    "    baseModel = 1\n",
    "\n",
    "    classifiers = ['KNN5', 'AdaBoost']\n",
    "\n",
    "    if baseModel == 1:\n",
    "        # Train classifier\n",
    "        for classifier in classifiers:\n",
    "            \n",
    "            print('\\nBaseline model:', classifier)\n",
    "\n",
    "            if classifier == \"KNN5\":\n",
    "                clf = KNeighborsClassifier(n_neighbors=5)\n",
    "            elif classifier == \"RF185\":\n",
    "                clf = RandomForestClassifier(n_estimators=185)\n",
    "            elif classifier == \"RF100\":\n",
    "                clf = RandomForestClassifier(n_estimators=100)\n",
    "            elif classifier == \"AdaBoost\":\n",
    "                clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "            #clf = ExtraTreesClassifier(n_estimators=100)\n",
    "            #clf = AdaBoostClassifier(n_estimators=185)\n",
    "            #clf = svm.LinearSVC()\n",
    "            #clf = GaussianNB()\n",
    "            #clf = DecisionTreeClassifier()\n",
    "            #clf = LogisticRegression()\n",
    "\n",
    "            clf.fit(X_T,Y_T)\n",
    "            y_pred = clf.predict(X_T)\n",
    "\n",
    "            prec_pos, recall_pos, f1_pos, TPR, FPR, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(Y_T, y_pred)\n",
    "\n",
    "            \n",
    "    \n",
    "\n",
    "# '''\n",
    "#     Strong classifier -- modified Adaboost\n",
    "# '''\n",
    "\n",
    "    from numpy import vectorize\n",
    "    from sklearn.tree import *\n",
    "\n",
    "    mdlpath = './model/'\n",
    "    \n",
    "    saveFinish = buildStrongClfDefThres(XY, 10, mdlpath)\n",
    "\n",
    "    assert  saveFinish == 1\n",
    "\n",
    "    yRes, clfThres = loadStrongClfDefThres(XY, 10, mdlpath)\n",
    "    \n",
    "    print(\"clfThres: \", clfThres,\"\\n\")\n",
    "    prec_pos, recall_pos, f1_pos, TPR, FPR, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XY[:,-1], yRes)\n",
    "    \n",
    "    print(\"\\nrecall_pos: \",recall_pos,'\\n')\n",
    "    print(\"prec_pos: \", prec_pos, '\\n')\n",
    "    print(\"false positive rate: \", FPR, '\\n')\n",
    "    \n",
    "    for clfThres in range(1,20,5):\n",
    "        \n",
    "        yRes = loadStrongClfAdjThres(XY, 10, mdlpath ,clfThres)\n",
    "        print(\"clfThres: \", clfThres)\n",
    "\n",
    "        prec_pos, recall_pos, f1_pos, TPR, FPR, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XY[:,-1], yRes)\n",
    "\n",
    "        print(\"recall_pos: \",recall_pos)\n",
    "        print(\"prec_pos: \", prec_pos)\n",
    "        print(\"false positive rate: \", FPR, '\\n')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    featList = [23,24,21,28,8,3,4,1,7,14,27,11,13,26,6,17,18,22,2,29,16,25,9,5,30,20,19,10,12,15]\n",
    "    print(len(featList))\n",
    "        \n",
    "        \n",
    "        \n",
    "    f = 0.7\n",
    "    d = 0.95\n",
    "\n",
    "    FTar = 0.1\n",
    "\n",
    "    FList = []\n",
    "    clfThresList = []\n",
    "    F = 1 #F0\n",
    "    FPrev = 0\n",
    "    D = 1 #D0\n",
    "    DPrev = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    datasets = ['feeding' , 'cancer']\n",
    "    dataset = datasets[1]\n",
    "    print('dataset:', dataset)\n",
    "    XY = loadDataset(dataset)\n",
    "\n",
    "    # initialization\n",
    "    XYPos =  XY[np.where(XY[:,-1]==1)[0],:]\n",
    "    XYNeg =  XY[np.where(XY[:,-1]==0)[0],:]\n",
    "\n",
    "    XYPosTrn, XYPosTest = tt_split(XYPos, 0.3)\n",
    "    XYNegTrn, XYNegTest = tt_split(XYNeg, 0.3)\n",
    "\n",
    "    P = XYPosTrn\n",
    "    N = XYNegTrn\n",
    "\n",
    "\n",
    "    XYTrn = np.vstack((XYPosTrn,XYNegTrn))\n",
    "    XYTest = np.vstack((XYPosTest,XYNegTest))\n",
    "\n",
    "\n",
    "    nFeats = 1\n",
    "    feats = featList[:nFeats]\n",
    "    XYTrnNFeat = np.hstack((XYTrn[:,feats], XYTrn[:,-1].reshape([-1,1])))\n",
    "    XYTestNFeat = np.hstack((XYTest[:,feats], XYTest[:,-1].reshape([-1,1])))\n",
    "    print('XYTestNFeat:')\n",
    "    print(XYTestNFeat.shape)\n",
    "\n",
    "\n",
    "\n",
    "    T = 100\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    mdlpath = './model_stage'+str(i)+'/'\n",
    "    saveFinish = buildStrongClfDefThres(XYTrnNFeat, T, mdlpath)\n",
    "    assert saveFinish\n",
    "\n",
    "\n",
    "    #       evaluate cascaded classifier on validation set to determine F and D\n",
    "    yRes, clfThres = loadStrongClfDefThres(XYTestNFeat, T, mdlpath)\n",
    "\n",
    "    print(\"clfThres: \", clfThres,\"\\n\")\n",
    "    prec_pos, D, f1_pos, TPR, F, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat[:,-1], yRes)\n",
    "    print(\"\\nrecall_pos: \",D,'\\n')\n",
    "    print(\"false positive rate: \", F, '\\n')\n",
    "\n",
    "\n",
    "    # # \n",
    "    # # plot to show ROC curve\n",
    "    # # \n",
    "    # recalls = np.zeros(int(clfThres)+9)\n",
    "    # FPRs = np.zeros(int(clfThres)+9)\n",
    "\n",
    "    # i = 0\n",
    "    # for clfThres in range(1,int(clfThres)+10):\n",
    "\n",
    "    #     yRes = loadStrongClfAdjThres(XYTestNFeat, T, mdlpath ,clfThres)\n",
    "    # #     print(\"clfThres: \", clfThres)\n",
    "    #     prec_pos, recalls[i], f1_pos, TPR, FPRs[i], Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat[:,-1], yRes)\n",
    "\n",
    "    # #     print(\"false positive rate: \", FPR, '\\n')\n",
    "    #     i = i + 1\n",
    "\n",
    "    # plt.figure(1)\n",
    "    # plt.plot(FPRs, recalls)\n",
    "    # plt.axvline(0.3, color='k', linestyle='--')\n",
    "    # plt.axhline(0.95, color='k', linestyle='--')\n",
    "\n",
    "\n",
    "    # featInd = []\n",
    "    # for i in range(T):\n",
    "    #     configFile = mdlpath + str(i) + '_feat.sav'\n",
    "    #     with open(configFile, \"r\") as f:\n",
    "    #         array = []\n",
    "    #         for line in f:\n",
    "    #             array.append(line)\n",
    "    #         featInd.append(array[0])\n",
    "    # print(set(featInd))\n",
    "\n",
    "\n",
    "    # plt.xlabel('False positive rate')\n",
    "    # plt.ylabel('True positive rate')\n",
    "    # plt.title('ROC curve, # of features:'+ str(nFeats) +', rounds:'+str(T)+ ', feature:'+str(set(featInd)))\n",
    "\n",
    "\n",
    "\n",
    "    # \n",
    "    # find the first acceptable threshold during decreasing threshold\n",
    "    # \n",
    "\n",
    "    i = int(clfThres)\n",
    "    F = 1 \n",
    "    print(\"D:\",D)\n",
    "\n",
    "    while i > 1 and F > f and nFeats<30:\n",
    "\n",
    "        print('F is greater than set f')\n",
    "\n",
    "        while D < d:\n",
    "            print('D is less than set d')\n",
    "\n",
    "            clfThres = i - 1\n",
    "            yRes = loadStrongClfAdjThres(XYTestNFeat, T, mdlpath ,clfThres)\n",
    "            print(\"clfThres: \", clfThres)\n",
    "            prec_pos, D, f1_pos, TPR, F, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat[:,-1], yRes)\n",
    "\n",
    "            print(\"false positive rate: \", F, '\\n')\n",
    "            print(\"recall: \", D, '\\n')\n",
    "\n",
    "            i = i - 1\n",
    "\n",
    "    clfThresList.append(clfThres)\n",
    "    F1= F\n",
    "    FList.append(F)\n",
    "\n",
    "\n",
    "    yRes = loadStrongClfAdjThres(XYTestNFeat, T, './model_stage0/',clfThresList[0])\n",
    "    prec_pos, D0, f1_pos, TPR, F0, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat[:,-1], yRes)\n",
    "\n",
    "    print('D0:',D0)\n",
    "    \n",
    "    \n",
    "    XYTrn = updateTrnUsingFP_allTrueSamples(XYPosTrn, yRes, XYTestNFeat)\n",
    "    \n",
    "    \n",
    "    \n",
    "    nFeats = 2\n",
    "    feats = featList[:nFeats]\n",
    "    #    generate new train set and keep old test set, for the second stage\n",
    "    XYTrnNFeat = np.hstack((XYTrn[:,feats], XYTrn[:,-1].reshape([-1,1])))\n",
    "    XYTestNFeat = np.hstack((XYTest[:,feats], XYTest[:,-1].reshape([-1,1])))\n",
    "\n",
    "\n",
    "    T = 100\n",
    "\n",
    "    # stage 2\n",
    "    i = 1\n",
    "    mdlpath = './model_stage'+str(i)+'/'\n",
    "    saveFinish = buildStrongClfDefThres(XYTrnNFeat, T, mdlpath)\n",
    "    assert saveFinish\n",
    "\n",
    "\n",
    "    #       evaluate cascaded classifier on validation set to determine F and D\n",
    "    # load stage 1 to test on test set\n",
    "\n",
    "\n",
    "    XYTestNFeat0 = np.hstack((XYTestNFeat[:,:1].reshape(-1,1), XYTestNFeat[:,-1].reshape([-1,1])))\n",
    "    print(XYTestNFeat0.shape)\n",
    "\n",
    "    # load the tuned threshold\n",
    "    yRes = loadStrongClfAdjThres(XYTestNFeat, T, './model_stage0/',clfThresList[0])\n",
    "    prec_pos, D0, f1_pos, TPR, F0, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat[:,-1], yRes)\n",
    "\n",
    "    yLabel = XYTestNFeat[:,-1]\n",
    "    indList = []\n",
    "    for i in range(len(yRes)):\n",
    "        if yRes[i] == 1:\n",
    "            indList.append(i)\n",
    "\n",
    "    print(indList)\n",
    "    XYTestNFeat_1 = XYTestNFeat[indList,:]\n",
    "\n",
    "    yRes, clfThres = loadStrongClfDefThres(XYTestNFeat_1, T, './model_stage1/')\n",
    "    prec_pos, D1, f1_pos, TPR, F1, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat_1[:,-1], yRes)\n",
    "\n",
    "    print('Threshold: ', clfThres)\n",
    "    F = F0*F1\n",
    "    print('F0:',F0)\n",
    "    print('F1:',F1)\n",
    "    print('F:',F)\n",
    "    print('\\n')\n",
    "\n",
    "    D = D0*D1\n",
    "    print('D0:',D0)\n",
    "    print('D1:',D1)\n",
    "    print('D:',D)\n",
    "\n",
    "    i = int(clfThres)\n",
    "\n",
    "\n",
    "    while i > 1:\n",
    "\n",
    "        i = i - 5\n",
    "\n",
    "        yRes = loadStrongClfAdjThres(XYTestNFeat_1, T, './model_stage1/', i)\n",
    "        prec_pos, D1, f1_pos, TPR, F1, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat_1[:,-1], yRes)\n",
    "\n",
    "\n",
    "        print('Threshold: ', i)\n",
    "        F = F0*F1\n",
    "        print('F0:',F0)\n",
    "        print('F1:',F1)\n",
    "        print('F:',F)\n",
    "\n",
    "        D = D0*D1\n",
    "        print('D0:',D0)\n",
    "        print('D1:',D1)\n",
    "        print('D:',D)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nFeats = 5\n",
    "    feats = featList[:nFeats]\n",
    "    #    generate new train set and keep old test set, for the second stage\n",
    "    XYTrnNFeat = np.hstack((XYTrn[:,feats], XYTrn[:,-1].reshape([-1,1])))\n",
    "    XYTestNFeat = np.hstack((XYTest[:,feats], XYTest[:,-1].reshape([-1,1])))\n",
    "\n",
    "\n",
    "    T = 100\n",
    "\n",
    "    # stage 2\n",
    "    i = 1\n",
    "    mdlpath = './model_stage'+str(i)+'/'\n",
    "    saveFinish = buildStrongClfDefThres(XYTrnNFeat, T, mdlpath)\n",
    "    assert saveFinish\n",
    "\n",
    "\n",
    "    #       evaluate cascaded classifier on validation set to determine F and D\n",
    "    # load stage 1 to test on test set\n",
    "\n",
    "\n",
    "    XYTestNFeat0 = np.hstack((XYTestNFeat[:,:1].reshape(-1,1), XYTestNFeat[:,-1].reshape([-1,1])))\n",
    "    print(XYTestNFeat0.shape)\n",
    "\n",
    "    # load the tuned threshold\n",
    "    yRes = loadStrongClfAdjThres(XYTestNFeat, T, './model_stage0/',clfThresList[0])\n",
    "    prec_pos, D0, f1_pos, TPR, F0, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat[:,-1], yRes)\n",
    "\n",
    "\n",
    "    # update the test set by selecting positive samples after prediction \n",
    "    XYTestNFeat_1 = updateTestSetbySelPosSamples(XYTestNFeat, yRes)\n",
    "\n",
    "\n",
    "    yRes, clfThres = loadStrongClfDefThres(XYTestNFeat_1, T, './model_stage1/')\n",
    "    prec_pos, D1, f1_pos, TPR, F1, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat_1[:,-1], yRes)\n",
    "\n",
    "    print('Threshold: ', clfThres)\n",
    "    F = F0*F1\n",
    "    print('F0:',F0)\n",
    "    print('F1:',F1)\n",
    "    print('F:',F)\n",
    "    print('\\n')\n",
    "\n",
    "    D = D0*D1\n",
    "    print('D0:',D0)\n",
    "    print('D1:',D1)\n",
    "    print('D:',D)\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "    if D1 > d and F1 < f:\n",
    "        clfThresList.append(iThre)\n",
    "        F1= F\n",
    "        FList.append(F)\n",
    "        print('Succeed!')\n",
    "\n",
    "    else:\n",
    "\n",
    "        iThre = int(clfThres)\n",
    "\n",
    "        while iThre > 1 and D1 < d:\n",
    "            iThre = iThre - 5\n",
    "\n",
    "            yRes = loadStrongClfAdjThres(XYTestNFeat_1, T, './model_stage1/', iThre)\n",
    "            prec_pos, D1, f1_pos, TPR, F1, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat_1[:,-1], yRes)\n",
    "\n",
    "\n",
    "            print('Threshold: ', iThre)\n",
    "            F = F0*F1\n",
    "            print('F0:',F0)\n",
    "            print('F1:',F1)\n",
    "            print('F:',F)\n",
    "            print('\\n')\n",
    "\n",
    "\n",
    "            D = D0*D1\n",
    "            print('D0:',D0)\n",
    "            print('D1:',D1)\n",
    "            print('D:',D)\n",
    "            print('\\n')\n",
    "\n",
    "\n",
    "        if D1 > d:\n",
    "            if F1 < f:\n",
    "                clfThresList.append(iThre)\n",
    "                F1= F\n",
    "                FList.append(F)\n",
    "                print('Succeed!')\n",
    "            else:\n",
    "                print('Fail: F cannot be less than f when D is greater than or equal to d')\n",
    "        else:\n",
    "            print('Fail, D cannot be greater than or equal to d')\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "    print('overall FPRs in each step list: ', FList)\n",
    "    yLabel = XYTestNFeat[:,-1]\n",
    "    indList = []\n",
    "    for i in range(len(yRes)):\n",
    "        if yRes[i] == 1 and yLabel[i]==0:\n",
    "            indList.append(i)\n",
    "    print(indList)\n",
    "    N = XYTest[indList,:]\n",
    "    N_stage0 = N\n",
    "\n",
    "    P = XYPosTrn\n",
    "    XYTrn = np.vstack((P,N))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The first stage: set the threshold as 11,  D(recall) = .972, F(FPR) = .208\n",
    "## number of features: 1, rounds = 100\n",
    "\n",
    "### as F>F(target) = 0.1, so put false detections into set N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### choose FP samples and all true samples as TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def updateTrnUsingFP_allTrueSamples(XYPosTrn, yRes, XYTestNFeat):\n",
    "    yLabel = XYTestNFeat[:,-1]\n",
    "    indList = []\n",
    "\n",
    "    for i in range(len(yRes)):\n",
    "        if yRes[i] == 1 and yLabel[i]==0:\n",
    "            indList.append(i)\n",
    "    print(indList)\n",
    "    N = XYTest[indList,:]\n",
    "    N_stage0 = N\n",
    "\n",
    "    P = XYPosTrn\n",
    "    XYTrn = np.vstack((P,N))\n",
    "\n",
    "    print(len(XYTrn))\n",
    "\n",
    "    return XYTrn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAGE 2\n",
    "\n",
    "### Use P and updated N to train the second stage classifier, \n",
    "### Use test set and the whole cascaded clf(STAGE1&2) to test:\n",
    "\n",
    "\n",
    "\n",
    "### when #of feature = 2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nFeats = 2\n",
    "# feats = featList[:nFeats]\n",
    "# #    generate new train set and keep old test set, for the second stage\n",
    "# XYTrnNFeat = np.hstack((XYTrn[:,feats], XYTrn[:,-1].reshape([-1,1])))\n",
    "# XYTestNFeat = np.hstack((XYTest[:,feats], XYTest[:,-1].reshape([-1,1])))\n",
    "\n",
    "\n",
    "# T = 100\n",
    "\n",
    "# # stage 2\n",
    "# i = 1\n",
    "# mdlpath = './model_stage'+str(i)+'/'\n",
    "# saveFinish = buildStrongClfDefThres(XYTrnNFeat, T, mdlpath)\n",
    "# assert saveFinish\n",
    "\n",
    "\n",
    "# #       evaluate cascaded classifier on validation set to determine F and D\n",
    "# # load stage 1 to test on test set\n",
    "\n",
    "\n",
    "# XYTestNFeat0 = np.hstack((XYTestNFeat[:,:1].reshape(-1,1), XYTestNFeat[:,-1].reshape([-1,1])))\n",
    "# print(XYTestNFeat0.shape)\n",
    "\n",
    "# # load the tuned threshold\n",
    "# yRes = loadStrongClfAdjThres(XYTestNFeat, T, './model_stage0/',clfThresList[0])\n",
    "# prec_pos, D0, f1_pos, TPR, F0, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat[:,-1], yRes)\n",
    "\n",
    "# yLabel = XYTestNFeat[:,-1]\n",
    "# indList = []\n",
    "# for i in range(len(yRes)):\n",
    "#     if yRes[i] == 1:\n",
    "#         indList.append(i)\n",
    "        \n",
    "# print(indList)\n",
    "# XYTestNFeat_1 = XYTestNFeat[indList,:]\n",
    "\n",
    "# yRes, clfThres = loadStrongClfDefThres(XYTestNFeat_1, T, './model_stage1/')\n",
    "# prec_pos, D1, f1_pos, TPR, F1, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat_1[:,-1], yRes)\n",
    "\n",
    "# print('Threshold: ', clfThres)\n",
    "# F = F0*F1\n",
    "# print('F0:',F0)\n",
    "# print('F1:',F1)\n",
    "# print('F:',F)\n",
    "# print('\\n')\n",
    "\n",
    "# D = D0*D1\n",
    "# print('D0:',D0)\n",
    "# print('D1:',D1)\n",
    "# print('D:',D)\n",
    "\n",
    "# i = int(clfThres)\n",
    "\n",
    "\n",
    "# while i > 1:\n",
    "    \n",
    "#     i = i - 5\n",
    "\n",
    "#     yRes = loadStrongClfAdjThres(XYTestNFeat_1, T, './model_stage1/', i)\n",
    "#     prec_pos, D1, f1_pos, TPR, F1, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat_1[:,-1], yRes)\n",
    "\n",
    "\n",
    "#     print('Threshold: ', i)\n",
    "#     F = F0*F1\n",
    "#     print('F0:',F0)\n",
    "#     print('F1:',F1)\n",
    "#     print('F:',F)\n",
    "\n",
    "#     D = D0*D1\n",
    "#     print('D0:',D0)\n",
    "#     print('D1:',D1)\n",
    "#     print('D:',D)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So,  when # of features = 2, cannot satisfy requirement of f = 0.3 and d = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### same with # of features = 3\n",
    "## retry STAGE 2\n",
    "\n",
    "### when #of feature = 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#     nFeats = 5\n",
    "#     feats = featList[:nFeats]\n",
    "#     #    generate new train set and keep old test set, for the second stage\n",
    "#     XYTrnNFeat = np.hstack((XYTrn[:,feats], XYTrn[:,-1].reshape([-1,1])))\n",
    "#     XYTestNFeat = np.hstack((XYTest[:,feats], XYTest[:,-1].reshape([-1,1])))\n",
    "\n",
    "\n",
    "#     T = 100\n",
    "\n",
    "#     # stage 2\n",
    "#     i = 1\n",
    "#     mdlpath = './model_stage'+str(i)+'/'\n",
    "#     saveFinish = buildStrongClfDefThres(XYTrnNFeat, T, mdlpath)\n",
    "#     assert saveFinish\n",
    "\n",
    "\n",
    "#     #       evaluate cascaded classifier on validation set to determine F and D\n",
    "#     # load stage 1 to test on test set\n",
    "\n",
    "\n",
    "#     XYTestNFeat0 = np.hstack((XYTestNFeat[:,:1].reshape(-1,1), XYTestNFeat[:,-1].reshape([-1,1])))\n",
    "#     print(XYTestNFeat0.shape)\n",
    "\n",
    "#     # load the tuned threshold\n",
    "#     yRes = loadStrongClfAdjThres(XYTestNFeat, T, './model_stage0/',clfThresList[0])\n",
    "#     prec_pos, D0, f1_pos, TPR, F0, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat[:,-1], yRes)\n",
    "\n",
    "\n",
    "#     # update the test set by selecting positive samples after prediction \n",
    "#     XYTestNFeat_1 = updateTestSetbySelPosSamples(XYTestNFeat, yRes)\n",
    "\n",
    "\n",
    "#     yRes, clfThres = loadStrongClfDefThres(XYTestNFeat_1, T, './model_stage1/')\n",
    "#     prec_pos, D1, f1_pos, TPR, F1, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat_1[:,-1], yRes)\n",
    "\n",
    "#     print('Threshold: ', clfThres)\n",
    "#     F = F0*F1\n",
    "#     print('F0:',F0)\n",
    "#     print('F1:',F1)\n",
    "#     print('F:',F)\n",
    "#     print('\\n')\n",
    "\n",
    "#     D = D0*D1\n",
    "#     print('D0:',D0)\n",
    "#     print('D1:',D1)\n",
    "#     print('D:',D)\n",
    "#     print('\\n')\n",
    "\n",
    "\n",
    "#     if D1 > d and F1 < f:\n",
    "#         clfThresList.append(iThre)\n",
    "#         F1= F\n",
    "#         FList.append(F)\n",
    "#         print('Succeed!')\n",
    "\n",
    "#     else:\n",
    "\n",
    "#         iThre = int(clfThres)\n",
    "\n",
    "#         while iThre > 1 and D1 < d:\n",
    "#             iThre = iThre - 5\n",
    "\n",
    "#             yRes = loadStrongClfAdjThres(XYTestNFeat_1, T, './model_stage1/', iThre)\n",
    "#             prec_pos, D1, f1_pos, TPR, F1, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat_1[:,-1], yRes)\n",
    "\n",
    "\n",
    "#             print('Threshold: ', iThre)\n",
    "#             F = F0*F1\n",
    "#             print('F0:',F0)\n",
    "#             print('F1:',F1)\n",
    "#             print('F:',F)\n",
    "#             print('\\n')\n",
    "\n",
    "\n",
    "#             D = D0*D1\n",
    "#             print('D0:',D0)\n",
    "#             print('D1:',D1)\n",
    "#             print('D:',D)\n",
    "#             print('\\n')\n",
    "\n",
    "\n",
    "#         if D1 > d:\n",
    "#             if F1 < f:\n",
    "#                 clfThresList.append(iThre)\n",
    "#                 F1= F\n",
    "#                 FList.append(F)\n",
    "#                 print('Succeed!')\n",
    "#             else:\n",
    "#                 print('Fail: F cannot be less than f when D is greater than or equal to d')\n",
    "#         else:\n",
    "#             print('Fail, D cannot be greater than or equal to d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save Positive output as the train set for next stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('overall FPRs in each step list: ', FList)\n",
    "# yLabel = XYTestNFeat[:,-1]\n",
    "# indList = []\n",
    "# for i in range(len(yRes)):\n",
    "#     if yRes[i] == 1 and yLabel[i]==0:\n",
    "#         indList.append(i)\n",
    "# print(indList)\n",
    "# N = XYTest[indList,:]\n",
    "# N_stage0 = N\n",
    "\n",
    "# P = XYPosTrn\n",
    "# XYTrn = np.vstack((P,N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When # of features = 5, threshold = 10, \n",
    "F0: 0.208053691275\n",
    "F1: 0.645161290323\n",
    "F: 0.134228187919\n",
    "\n",
    "\n",
    "D0: 0.972222222222\n",
    "D1: 0.987755102041\n",
    "D: 0.960317460317\n",
    "\n",
    "## So stage 2:  features = 5, threshold = 10\n",
    "\n",
    "\n",
    "## Train Stage 3:\n",
    "\n",
    "### Try # of features: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nFeats = 10\n",
    "# feats = featList[:nFeats]\n",
    "# #    generate new train set and keep old test set, for the 3rd stage\n",
    "# XYTrnNFeat = np.hstack((XYTrn[:,feats], XYTrn[:,-1].reshape([-1,1])))\n",
    "# XYTestNFeat = np.hstack((XYTest[:,feats], XYTest[:,-1].reshape([-1,1])))\n",
    "\n",
    "\n",
    "# T = 100\n",
    "\n",
    "# # stage 3\n",
    "# i = 2\n",
    "# mdlpath = './model_stage'+str(i)+'/'\n",
    "# saveFinish = buildStrongClfDefThres(XYTrnNFeat, T, mdlpath)\n",
    "# assert saveFinish\n",
    "\n",
    "\n",
    "# #       evaluate cascaded classifier on validation set to determine F and D\n",
    "# # load stage 1 to test on test set\n",
    "\n",
    "# XYTestNFeat0 = np.hstack((XYTestNFeat[:,:1].reshape(-1,1), XYTestNFeat[:,-1].reshape([-1,1])))\n",
    "# print(XYTestNFeat0.shape)\n",
    "\n",
    "# # load the tuned threshold\n",
    "# yRes = loadStrongClfAdjThres(XYTestNFeat, T, './model_stage0/',clfThresList[0])\n",
    "# prec_pos, D0, f1_pos, TPR, F0, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat[:,-1], yRes)\n",
    "\n",
    "# yLabel = XYTestNFeat[:,-1]\n",
    "# indList = []\n",
    "# for i in range(len(yRes)):\n",
    "#     if yRes[i] == 1:\n",
    "#         indList.append(i)\n",
    "        \n",
    "# print(indList)\n",
    "# XYTestNFeat_1 = XYTestNFeat[indList,:]\n",
    "\n",
    "# yRes, clfThres = loadStrongClfDefThres(XYTestNFeat_1, T, './model_stage1/')\n",
    "# prec_pos, D1, f1_pos, TPR, F1, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat_1[:,-1], yRes)\n",
    "\n",
    "# print('Threshold: ', clfThres)\n",
    "# F = F0*F1\n",
    "# print('F0:',F0)\n",
    "# print('F1:',F1)\n",
    "# print('F:',F)\n",
    "# print('\\n')\n",
    "\n",
    "# D = D0*D1\n",
    "# print('D0:',D0)\n",
    "# print('D1:',D1)\n",
    "# print('D:',D)\n",
    "# print('\\n')\n",
    "\n",
    "\n",
    "# iThre = int(clfThres)\n",
    "\n",
    "\n",
    "# while iThre > 1 and D1 < d:\n",
    "#     iThre = iThre - 5\n",
    "\n",
    "#     yRes = loadStrongClfAdjThres(XYTestNFeat_1, T, './model_stage1/', iThre)\n",
    "#     prec_pos, D1, f1_pos, TPR, F1, Specificity, MCC, CKappa, w_acc, cm = calc_cm_rcall(XYTestNFeat_1[:,-1], yRes)\n",
    "\n",
    "\n",
    "#     print('Threshold: ', iThre)\n",
    "#     F = F0*F1\n",
    "#     print('F0:',F0)\n",
    "#     print('F1:',F1)\n",
    "#     print('F:',F)\n",
    "#     print('\\n')\n",
    "\n",
    "\n",
    "#     D = D0*D1\n",
    "#     print('D0:',D0)\n",
    "#     print('D1:',D1)\n",
    "#     print('D:',D)\n",
    "#     print('\\n')\n",
    "\n",
    "\n",
    "# if D1 > d:\n",
    "#     if F1 < f:\n",
    "#         clfThresList.append(iThre)\n",
    "#         F1= F\n",
    "#         FList.append(F)\n",
    "#     else:\n",
    "#         print('Fail: F cannot be less than f when D is greater than or equal to d')\n",
    "# else:\n",
    "#     print('Fail, D cannot be greater than or equal to d')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(D)\n",
    "# print(f*FList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Life is a journey. Don't get lost. \n",
    "# The TV show exibits all kinds of emotional issues. Almost everything in it exceeds the boundary that you can ever imagine. It shows all \n",
    "# I Never \n",
    "# \n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
